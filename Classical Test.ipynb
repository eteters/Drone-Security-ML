{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixDataset(csvName):\n",
    "    ids_1 = {\"count\":0}\n",
    "    ids_2 = {\"count\":0}\n",
    "    ids_3 = {\"count\":0}\n",
    "    ids_4 = {\"count\":0}\n",
    "\n",
    "    with open(csvName, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        text_file = open(\"newCsvDataset.txt\", \"w\")\n",
    "        for row in reader:\n",
    "            if row[0] == \"duration\":\n",
    "                for item in row:\n",
    "                    text_file.write(\"{},\".format(item))\n",
    "            else:\n",
    "                for row_i in range(len(row)):\n",
    "                    text = \"\"\n",
    "                    if row_i == 1:\n",
    "                        if row[row_i] in ids_1:\n",
    "                            text = str(ids_1[row[row_i]])\n",
    "                        else:\n",
    "                            ids_1[row[row_i]] = ids_1[\"count\"] \n",
    "                            ids_1[\"count\"] += 1\n",
    "                            text = str(ids_1[row[row_i]])\n",
    "                            \n",
    "                    elif row_i == 2:\n",
    "                        if row[row_i] in ids_2:\n",
    "                            text = str(ids_2[row[row_i]])\n",
    "                        else:\n",
    "                            ids_2[row[row_i]] = ids_2[\"count\"] \n",
    "                            ids_2[\"count\"] += 1\n",
    "                            text = str(ids_2[row[row_i]])\n",
    "                    elif row_i == 3:\n",
    "                        if row[row_i] in ids_3:\n",
    "                            text = str(ids_3[row[row_i]])\n",
    "                        else:\n",
    "                            ids_3[row[row_i]] = ids_3[\"count\"] \n",
    "                            ids_3[\"count\"] += 1\n",
    "                            text = str(ids_3[row[row_i]])\n",
    "                    elif row_i == 41:\n",
    "                        if row[row_i] in ids_4:\n",
    "                            text = str(ids_4[row[row_i]])\n",
    "                        else:\n",
    "                            ids_4[row[row_i]] = ids_4[\"count\"] \n",
    "                            ids_4[\"count\"] += 1\n",
    "                            text = str(ids_4[row[row_i]])\n",
    "                    else:\n",
    "                        text = row[row_i]\n",
    "                        \n",
    "                    text_file.write(\"{},\".format(text))\n",
    "            \n",
    "    return [ids_1,ids_2,ids_3,ids_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'count': 3, 'tcp': 0, 'icmp': 1, 'udp': 2},\n",
       " {'count': 64,\n",
       "  'private': 0,\n",
       "  'ftp_data': 1,\n",
       "  'eco_i': 2,\n",
       "  'telnet': 3,\n",
       "  'http': 4,\n",
       "  'smtp': 5,\n",
       "  'ftp': 6,\n",
       "  'ldap': 7,\n",
       "  'pop_3': 8,\n",
       "  'courier': 9,\n",
       "  'discard': 10,\n",
       "  'ecr_i': 11,\n",
       "  'imap4': 12,\n",
       "  'domain_u': 13,\n",
       "  'mtp': 14,\n",
       "  'systat': 15,\n",
       "  'iso_tsap': 16,\n",
       "  'other': 17,\n",
       "  'csnet_ns': 18,\n",
       "  'finger': 19,\n",
       "  'uucp': 20,\n",
       "  'whois': 21,\n",
       "  'netbios_ns': 22,\n",
       "  'link': 23,\n",
       "  'Z39_50': 24,\n",
       "  'sunrpc': 25,\n",
       "  'auth': 26,\n",
       "  'netbios_dgm': 27,\n",
       "  'uucp_path': 28,\n",
       "  'vmnet': 29,\n",
       "  'domain': 30,\n",
       "  'name': 31,\n",
       "  'pop_2': 32,\n",
       "  'http_443': 33,\n",
       "  'urp_i': 34,\n",
       "  'login': 35,\n",
       "  'gopher': 36,\n",
       "  'exec': 37,\n",
       "  'time': 38,\n",
       "  'remote_job': 39,\n",
       "  'ssh': 40,\n",
       "  'kshell': 41,\n",
       "  'sql_net': 42,\n",
       "  'shell': 43,\n",
       "  'hostnames': 44,\n",
       "  'echo': 45,\n",
       "  'daytime': 46,\n",
       "  'pm_dump': 47,\n",
       "  'IRC': 48,\n",
       "  'netstat': 49,\n",
       "  'ctf': 50,\n",
       "  'nntp': 51,\n",
       "  'netbios_ssn': 52,\n",
       "  'tim_i': 53,\n",
       "  'supdup': 54,\n",
       "  'bgp': 55,\n",
       "  'nnsp': 56,\n",
       "  'rje': 57,\n",
       "  'printer': 58,\n",
       "  'efs': 59,\n",
       "  'X11': 60,\n",
       "  'ntp_u': 61,\n",
       "  'klogin': 62,\n",
       "  'tftp_u': 63},\n",
       " {'count': 11,\n",
       "  'REJ': 0,\n",
       "  'SF': 1,\n",
       "  'RSTO': 2,\n",
       "  'S0': 3,\n",
       "  'RSTR': 4,\n",
       "  'SH': 5,\n",
       "  'S3': 6,\n",
       "  'S2': 7,\n",
       "  'S1': 8,\n",
       "  'RSTOS0': 9,\n",
       "  'OTH': 10},\n",
       " {'count': 38,\n",
       "  'neptune': 0,\n",
       "  'normal': 1,\n",
       "  'saint': 2,\n",
       "  'mscan': 3,\n",
       "  'guess_passwd': 4,\n",
       "  'smurf': 5,\n",
       "  'apache2': 6,\n",
       "  'satan': 7,\n",
       "  'buffer_overflow': 8,\n",
       "  'back': 9,\n",
       "  'warezmaster': 10,\n",
       "  'snmpgetattack': 11,\n",
       "  'processtable': 12,\n",
       "  'pod': 13,\n",
       "  'httptunnel': 14,\n",
       "  'nmap': 15,\n",
       "  'ps': 16,\n",
       "  'snmpguess': 17,\n",
       "  'ipsweep': 18,\n",
       "  'mailbomb': 19,\n",
       "  'portsweep': 20,\n",
       "  'multihop': 21,\n",
       "  'named': 22,\n",
       "  'sendmail': 23,\n",
       "  'loadmodule': 24,\n",
       "  'xterm': 25,\n",
       "  'worm': 26,\n",
       "  'teardrop': 27,\n",
       "  'rootkit': 28,\n",
       "  'xlock': 29,\n",
       "  'perl': 30,\n",
       "  'land': 31,\n",
       "  'xsnoop': 32,\n",
       "  'sqlattack': 33,\n",
       "  'ftp_write': 34,\n",
       "  'imap': 35,\n",
       "  'udpstorm': 36,\n",
       "  'phf': 37}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixDataset(\"kddtest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************************************************\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import Normalizer\n",
    "# from pandas_ml import ConfusionMatrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"***************************************************************\")\n",
    "\n",
    "traindata = pd.read_csv('kddtrain-20-mod.csv', dtype={\"protocol_type\":np.str, \"service\": np.str, \"flag\": np.str, \"attack_type\": np.str}, header=0)\n",
    "testdata = pd.read_csv('kddtest-mod.csv', dtype={\"protocol_type\":np.str, \"service\": np.str, \"flag\": np.str, \"attack_type\": np.str}, header=0)\n",
    "\n",
    "X = traindata.iloc[:,1:42]\n",
    "Y = traindata.iloc[:,0]\n",
    "C = testdata.iloc[:,0]\n",
    "T = testdata.iloc[:,1:42]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "\n",
    "\n",
    "traindata = np.array(trainX)\n",
    "trainlabel = np.array(Y)\n",
    "\n",
    "testdata = np.array(testT)\n",
    "testlabel = np.array(C)\n",
    "\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(traindata, trainlabel)\n",
    "\n",
    "\n",
    "# make predictions\n",
    "expected = testlabel\n",
    "predicted = model.predict(testdata)\n",
    "\n",
    "\n",
    "print(\"***************************************************************\")\n",
    "\n",
    "\n",
    "\n",
    "# fit a Naive Bayes model to the data\n",
    "model = GaussianNB()\n",
    "model.fit(traindata, trainlabel)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = testlabel\n",
    "predicted = model.predict(testdata)\n",
    "\n",
    "cm = confusion_matrix(expected, predicted)\n",
    "print(expected.shape)\n",
    "print(predicted.shape)\n",
    "expected = np.array(expected)\n",
    "predicted = np.array(predicted)\n",
    "cm.print_stats()\n",
    "\n",
    "np.savetxt('expected.txt', expected, fmt='%01d')\n",
    "np.savetxt('predicted.txt',predicted , fmt='%01d')\n",
    "\n",
    "print(cm)\n",
    "print(expected.shape)\n",
    "print(predicted.shape)\n",
    "cm.stats()\n",
    "print(\"***************************************************************\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fit a k-nearest neighbor model to the data\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(traindata, trainlabel)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = testlabel\n",
    "predicted = model.predict(testdata)\n",
    "# summarize the fit of the model\n",
    "\n",
    "cm = metrics.confusion_matrix(expected, predicted)\n",
    "print(cm)\n",
    "tpr = float(cm[0][0])/np.sum(cm[0])\n",
    "fpr = float(cm[1][1])/np.sum(cm[1])\n",
    "print(\"%.3f\" %tpr)\n",
    "print(\"%.3f\" %fpr)\n",
    "print(\"Accuracy\")\n",
    "print(\"%.3f\" %accuracy)\n",
    "print(\"precision\")\n",
    "print(\"%.3f\" %precision)\n",
    "print(\"recall\")\n",
    "print(\"%.3f\" %recall)\n",
    "print(\"f-score\")\n",
    "print(\"%.3f\" %f1)\n",
    "print(\"fpr\")\n",
    "print(\"%.3f\" %fpr)\n",
    "print(\"tpr\")\n",
    "print(\"%.3f\" %tpr)\n",
    "print(\"***************************************************************\")\n",
    "\n",
    "\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(traindata, trainlabel)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = testlabel\n",
    "predicted = model.predict(testdata)\n",
    "# summarize the fit of the model\n",
    "\n",
    "cm = metrics.confusion_matrix(expected, predicted)\n",
    "print(cm)\n",
    "tpr = float(cm[0][0])/np.sum(cm[0])\n",
    "fpr = float(cm[1][1])/np.sum(cm[1])\n",
    "print(\"%.3f\" %tpr)\n",
    "print(\"%.3f\" %fpr)\n",
    "print(\"Accuracy\")\n",
    "print(\"%.3f\" %accuracy)\n",
    "print(\"precision\")\n",
    "print(\"%.3f\" %precision)\n",
    "print(\"recall\")\n",
    "print(\"%.3f\" %recall)\n",
    "print(\"f-score\")\n",
    "print(\"%.3f\" %f1)\n",
    "print(\"fpr\")\n",
    "print(\"%.3f\" %fpr)\n",
    "print(\"tpr\")\n",
    "print(\"%.3f\" %tpr)\n",
    "print(\"***************************************************************\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = AdaBoostClassifier(n_estimators=100)\n",
    "model.fit(traindata, trainlabel)\n",
    "\n",
    "# make predictions\n",
    "expected = testlabel\n",
    "predicted = model.predict(testdata)\n",
    "# summarize the fit of the model\n",
    "\n",
    "cm = metrics.confusion_matrix(expected, predicted)\n",
    "print(cm)\n",
    "tpr = float(cm[0][0])/np.sum(cm[0])\n",
    "fpr = float(cm[1][1])/np.sum(cm[1])\n",
    "print(\"%.3f\" %tpr)\n",
    "print(\"%.3f\" %fpr)\n",
    "print(\"Accuracy\")\n",
    "print(\"%.3f\" %accuracy)\n",
    "print(\"precision\")\n",
    "print(\"%.3f\" %precision)\n",
    "print(\"recall\")\n",
    "print(\"%.3f\" %recall)\n",
    "print(\"f-score\")\n",
    "print(\"%.3f\" %f1)\n",
    "print(\"fpr\")\n",
    "print(\"%.3f\" %fpr)\n",
    "print(\"tpr\")\n",
    "print(\"%.3f\" %tpr)\n",
    "print(\"***************************************************************\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model = clf.fit(traindata, trainlabel)\n",
    "\n",
    "# make predictions\n",
    "expected = testlabel\n",
    "predicted = model.predict(testdata)\n",
    "# summarize the fit of the model\n",
    "\n",
    "cm = metrics.confusion_matrix(expected, predicted)\n",
    "print(cm)\n",
    "tpr = float(cm[0][0])/np.sum(cm[0])\n",
    "fpr = float(cm[1][1])/np.sum(cm[1])\n",
    "print(\"%.3f\" %tpr)\n",
    "print(\"%.3f\" %fpr)\n",
    "print(\"Accuracy\")\n",
    "print(\"%.3f\" %accuracy)\n",
    "print(\"precision\")\n",
    "print(\"%.3f\" %precision)\n",
    "print(\"recall\")\n",
    "print(\"%.3f\" %recall)\n",
    "print(\"f-score\")\n",
    "print(\"%.3f\" %f1)\n",
    "print(\"fpr\")\n",
    "print(\"%.3f\" %fpr)\n",
    "print(\"tpr\")\n",
    "print(\"%.3f\" %tpr)\n",
    "print(\"***************************************************************\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
