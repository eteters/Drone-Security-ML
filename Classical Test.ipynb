{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import Normalizer\n",
    "# from pandas_ml import ConfusionMatrix\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixDataset(csvName):\n",
    "    ids_1 = {\"count\":0}\n",
    "    ids_2 = {\"count\":0}\n",
    "    ids_3 = {\"count\":0}\n",
    "    ids_4 = {\"count\":0}\n",
    "\n",
    "    with open(csvName, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        text_file = open(\"newCsvDataset.txt\", \"w\")\n",
    "        for row in reader:\n",
    "            for row_i in range(len(row)):\n",
    "                text = \"\"\n",
    "                if row_i == 1:\n",
    "                    if row[row_i] in ids_1:\n",
    "                        text = str(ids_1[row[row_i]])\n",
    "                    else:\n",
    "                        ids_1[row[row_i]] = ids_1[\"count\"] \n",
    "                        ids_1[\"count\"] += 1\n",
    "                        text = str(ids_1[row[row_i]])\n",
    "\n",
    "                elif row_i == 2:\n",
    "                    if row[row_i] in ids_2:\n",
    "                        text = str(ids_2[row[row_i]])\n",
    "                    else:\n",
    "                        ids_2[row[row_i]] = ids_2[\"count\"] \n",
    "                        ids_2[\"count\"] += 1\n",
    "                        text = str(ids_2[row[row_i]])\n",
    "                elif row_i == 3:\n",
    "                    if row[row_i] in ids_3:\n",
    "                        text = str(ids_3[row[row_i]])\n",
    "                    else:\n",
    "                        ids_3[row[row_i]] = ids_3[\"count\"] \n",
    "                        ids_3[\"count\"] += 1\n",
    "                        text = str(ids_3[row[row_i]])\n",
    "                elif row_i == 41:\n",
    "                    if row[row_i] in ids_4:\n",
    "                        text = str(ids_4[row[row_i]])\n",
    "                    else:\n",
    "                        ids_4[row[row_i]] = ids_4[\"count\"] \n",
    "                        ids_4[\"count\"] += 1\n",
    "                        text = str(ids_4[row[row_i]])\n",
    "                else:\n",
    "                    text = row[row_i]\n",
    "\n",
    "                text_file.write(\"{},\".format(text))\n",
    "            text_file.write('\\n')\n",
    "\n",
    "    return [ids_1,ids_2,ids_3,ids_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'count': 3, 'tcp': 0, 'udp': 1, 'icmp': 2},\n",
       " {'count': 70,\n",
       "  'ftp_data': 0,\n",
       "  'other': 1,\n",
       "  'private': 2,\n",
       "  'http': 3,\n",
       "  'remote_job': 4,\n",
       "  'name': 5,\n",
       "  'netbios_ns': 6,\n",
       "  'eco_i': 7,\n",
       "  'mtp': 8,\n",
       "  'telnet': 9,\n",
       "  'finger': 10,\n",
       "  'domain_u': 11,\n",
       "  'supdup': 12,\n",
       "  'uucp_path': 13,\n",
       "  'Z39_50': 14,\n",
       "  'smtp': 15,\n",
       "  'csnet_ns': 16,\n",
       "  'uucp': 17,\n",
       "  'netbios_dgm': 18,\n",
       "  'urp_i': 19,\n",
       "  'auth': 20,\n",
       "  'domain': 21,\n",
       "  'ftp': 22,\n",
       "  'bgp': 23,\n",
       "  'ldap': 24,\n",
       "  'ecr_i': 25,\n",
       "  'gopher': 26,\n",
       "  'vmnet': 27,\n",
       "  'systat': 28,\n",
       "  'http_443': 29,\n",
       "  'efs': 30,\n",
       "  'whois': 31,\n",
       "  'imap4': 32,\n",
       "  'iso_tsap': 33,\n",
       "  'echo': 34,\n",
       "  'klogin': 35,\n",
       "  'link': 36,\n",
       "  'sunrpc': 37,\n",
       "  'login': 38,\n",
       "  'kshell': 39,\n",
       "  'sql_net': 40,\n",
       "  'time': 41,\n",
       "  'hostnames': 42,\n",
       "  'exec': 43,\n",
       "  'ntp_u': 44,\n",
       "  'discard': 45,\n",
       "  'nntp': 46,\n",
       "  'courier': 47,\n",
       "  'ctf': 48,\n",
       "  'ssh': 49,\n",
       "  'daytime': 50,\n",
       "  'shell': 51,\n",
       "  'netstat': 52,\n",
       "  'pop_3': 53,\n",
       "  'nnsp': 54,\n",
       "  'IRC': 55,\n",
       "  'pop_2': 56,\n",
       "  'printer': 57,\n",
       "  'tim_i': 58,\n",
       "  'pm_dump': 59,\n",
       "  'red_i': 60,\n",
       "  'netbios_ssn': 61,\n",
       "  'rje': 62,\n",
       "  'X11': 63,\n",
       "  'urh_i': 64,\n",
       "  'http_8001': 65,\n",
       "  'aol': 66,\n",
       "  'http_2784': 67,\n",
       "  'tftp_u': 68,\n",
       "  'harvest': 69},\n",
       " {'count': 11,\n",
       "  'SF': 0,\n",
       "  'S0': 1,\n",
       "  'REJ': 2,\n",
       "  'RSTR': 3,\n",
       "  'SH': 4,\n",
       "  'RSTO': 5,\n",
       "  'S1': 6,\n",
       "  'RSTOS0': 7,\n",
       "  'S3': 8,\n",
       "  'S2': 9,\n",
       "  'OTH': 10},\n",
       " {'count': 23,\n",
       "  'normal': 0,\n",
       "  'neptune': 1,\n",
       "  'warezclient': 2,\n",
       "  'ipsweep': 3,\n",
       "  'portsweep': 4,\n",
       "  'teardrop': 5,\n",
       "  'nmap': 6,\n",
       "  'satan': 7,\n",
       "  'smurf': 8,\n",
       "  'pod': 9,\n",
       "  'back': 10,\n",
       "  'guess_passwd': 11,\n",
       "  'ftp_write': 12,\n",
       "  'multihop': 13,\n",
       "  'rootkit': 14,\n",
       "  'buffer_overflow': 15,\n",
       "  'imap': 16,\n",
       "  'warezmaster': 17,\n",
       "  'phf': 18,\n",
       "  'land': 19,\n",
       "  'loadmodule': 20,\n",
       "  'spy': 21,\n",
       "  'perl': 22}]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixDataset(\"kddtrain.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************************************************\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"***************************************************************\")\n",
    "\n",
    "traindata = pd.read_csv('kddtrain-20-mod.csv', header=None)\n",
    "testdata = pd.read_csv('kddtest-mod.csv', header=None)\n",
    "\n",
    "X = traindata.iloc[:,1:42]\n",
    "Y = traindata.iloc[:,0]\n",
    "C = testdata.iloc[:,0]\n",
    "T = testdata.iloc[:,1:42]\n",
    "\n",
    "scaler = Normalizer().fit(X)\n",
    "trainX = scaler.transform(X)\n",
    "\n",
    "scaler = Normalizer().fit(T)\n",
    "testT = scaler.transform(T)\n",
    "\n",
    "\n",
    "traindata = np.array(trainX)\n",
    "trainlabel = np.array(Y)\n",
    "\n",
    "testdata = np.array(testT)\n",
    "testlabel = np.array(C)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evanteters/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************************************************\n"
     ]
    }
   ],
   "source": [
    "print(\"***************************************************************\")\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(traindata, trainlabel)\n",
    "\n",
    "\n",
    "# make predictions\n",
    "expected = testlabel\n",
    "predicted = model.predict(testdata)\n",
    "\n",
    "\n",
    "print(\"***************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************************************************\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "(22544,)\n",
      "(22544,)\n",
      "[[4955   19    9 ...    0    0    0]\n",
      " [  50    2    1 ...    0    0    0]\n",
      " [  23    0    0 ...    0    0    0]\n",
      " ...\n",
      " [   0    0    0 ...    0    0    0]\n",
      " [   0    0    0 ...    0    0    0]\n",
      " [   0    0    0 ...    0    0    0]]\n",
      "(22544,)\n",
      "(22544,)\n",
      "Acc: 0.22130056738431864 prec: 0.0016383966783433057 recall: 0.003077566135099834 F1: 0.002138385874780905\n",
      "***************************************************************\n"
     ]
    }
   ],
   "source": [
    "print(\"***************************************************************\")\n",
    "\n",
    "# fit a Naive Bayes model to the data\n",
    "model = GaussianNB()\n",
    "model.fit(traindata, trainlabel)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = testlabel\n",
    "predicted = model.predict(testdata)\n",
    "\n",
    "cm = confusion_matrix(expected, predicted)\n",
    "print(expected.shape)\n",
    "print(predicted.shape)\n",
    "expected = np.array(expected)\n",
    "predicted = np.array(predicted)\n",
    "# cm.print_stats()\n",
    "\n",
    "np.savetxt('expected.txt', expected, fmt='%01d')\n",
    "np.savetxt('predicted.txt',predicted , fmt='%01d')\n",
    "\n",
    "print(cm)\n",
    "print(expected.shape)\n",
    "print(predicted.shape)\n",
    "evaluateCM(cm)\n",
    "# cm.stats()\n",
    "print(\"***************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************************************************\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "[[18888    62    15 ...     0     0     0]\n",
      " [  556    22     5 ...     0     0     0]\n",
      " [   99     3     0 ...     0     0     0]\n",
      " ...\n",
      " [    0     0     0 ...     0     0     0]\n",
      " [    0     0     0 ...     0     0     0]\n",
      " [    1     0     0 ...     0     0     0]]\n",
      "0.993\n",
      "0.037\n",
      "Acc: 0.8389371879936538 prec: 0.0022566436000410286 recall: 0.0034464149714222908 F1: 0.0027274243078131847\n",
      "***************************************************************\n"
     ]
    }
   ],
   "source": [
    "print(\"***************************************************************\")\n",
    "# fit a k-nearest neighbor model to the data\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(traindata, trainlabel)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = testlabel\n",
    "predicted = model.predict(testdata)\n",
    "# summarize the fit of the model\n",
    "\n",
    "cm = metrics.confusion_matrix(expected, predicted)\n",
    "print(cm)\n",
    "tpr = float(cm[0][0])/np.sum(cm[0])\n",
    "fpr = float(cm[1][1])/np.sum(cm[1])\n",
    "print(\"%.3f\" %tpr)\n",
    "print(\"%.3f\" %fpr)\n",
    "evaluateCM(cm)\n",
    "print(\"***************************************************************\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************************************************\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "[[16437   257    57 ...     0     0     0]\n",
      " [  148    44     7 ...     0     0     0]\n",
      " [   50    17     3 ...     0     0     0]\n",
      " ...\n",
      " [    1     0     0 ...     0     0     0]\n",
      " [    1     0     0 ...     0     0     0]\n",
      " [    0     0     0 ...     0     0     0]]\n",
      "0.864\n",
      "0.075\n",
      "Acc: 0.7317246259238337 prec: 0.002660768641334352 recall: 0.0036341434326750354 F1: 0.0030722001419835852\n",
      "***************************************************************\n"
     ]
    }
   ],
   "source": [
    "print(\"***************************************************************\")\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(traindata, trainlabel)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = testlabel\n",
    "predicted = model.predict(testdata)\n",
    "# summarize the fit of the model\n",
    "\n",
    "cm = metrics.confusion_matrix(expected, predicted)\n",
    "print(cm)\n",
    "tpr = float(cm[0][0])/np.sum(cm[0])\n",
    "fpr = float(cm[1][1])/np.sum(cm[1])\n",
    "print(\"%.3f\" %tpr)\n",
    "print(\"%.3f\" %fpr)\n",
    "evaluateCM(cm)\n",
    "print(\"***************************************************************\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************************************************\n",
      "[[19017     0     0 ...     0     0     0]\n",
      " [  587     0     0 ...     0     0     0]\n",
      " [  103     0     0 ...     0     0     0]\n",
      " ...\n",
      " [    1     0     0 ...     0     0     0]\n",
      " [    1     0     0 ...     0     0     0]\n",
      " [    1     0     0 ...     0     0     0]]\n",
      "1.000\n",
      "0.000\n",
      "Acc: 0.8435503888888981 prec: 0.001602475943964015 recall: 0.002944740254696747 F1: 0.002075500795745669\n",
      "***************************************************************\n"
     ]
    }
   ],
   "source": [
    "print(\"***************************************************************\")\n",
    "model = AdaBoostClassifier(n_estimators=100)\n",
    "model.fit(traindata, trainlabel)\n",
    "\n",
    "# make predictions\n",
    "expected = testlabel\n",
    "predicted = model.predict(testdata)\n",
    "# summarize the fit of the model\n",
    "\n",
    "cm = metrics.confusion_matrix(expected, predicted)\n",
    "print(cm)\n",
    "tpr = float(cm[0][0])/np.sum(cm[0])\n",
    "fpr = float(cm[1][1])/np.sum(cm[1])\n",
    "print(\"%.3f\" %tpr)\n",
    "print(\"%.3f\" %fpr)\n",
    "evaluateCM(cm)\n",
    "\n",
    "print(\"***************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************************************************\n",
      "[[18997    18     2 ...     0     0     0]\n",
      " [  561    24     1 ...     0     0     0]\n",
      " [   96     6     0 ...     0     0     0]\n",
      " ...\n",
      " [    1     0     0 ...     0     0     0]\n",
      " [    1     0     0 ...     0     0     0]\n",
      " [    1     0     0 ...     0     0     0]]\n",
      "Acc: 0.8439939658316863 prec: 0.004360444025732532 recall: 0.0051841728457411975 F1: 0.004736763312341666\n",
      "***************************************************************\n"
     ]
    }
   ],
   "source": [
    "print(\"***************************************************************\")\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model = model.fit(traindata, trainlabel)\n",
    "\n",
    "# make predictions\n",
    "expected = testlabel\n",
    "predicted = model.predict(testdata)\n",
    "# summarize the fit of the model\n",
    "\n",
    "cm = metrics.confusion_matrix(expected, predicted)\n",
    "print(cm)\n",
    "# tpr = float(cm[0][0])/np.sum(cm[0])\n",
    "# fpr = float(cm[1][1])/np.sum(cm[1])\n",
    "evaluateCM(cm)\n",
    "\n",
    "print(\"***************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateCM(ConfusionMatrix):\n",
    "    ConfusionMatrix = np.add(ConfusionMatrix, 0.0000000001)\n",
    "#     print(\"sum is \", np.sum(ConfusionMatrix))\n",
    "    accuracy = np.sum(ConfusionMatrix.diagonal()) / np.sum(ConfusionMatrix)\n",
    "#     print(\"sum a1 is \", np.sum(ConfusionMatrix, axis = 1))\n",
    "    precision = ConfusionMatrix.diagonal() / np.sum(ConfusionMatrix, axis = 1)\n",
    "#     print(\"sum a0 is \", np.sum(ConfusionMatrix, axis = 0))\n",
    "    recall = ConfusionMatrix.diagonal() / np.sum(ConfusionMatrix, axis = 0)\n",
    "\n",
    "    precision = np.mean(precision)\n",
    "    recall = np.mean(recall)\n",
    "    F1 = 2* ((precision * recall ) / (precision + recall))\n",
    "\n",
    "    print(\"Acc:\", accuracy, \"prec:\", precision, \"recall:\", recall, \"F1:\", F1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
